{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则表达式操作\n",
    "* 一个正则表达式（或RE）指定了一集与之匹配的字符串；模块内的函数可以让你检查某个字符串是否跟给定的正则表达式匹配（或者一个正则表达式是否匹配到一个字符串，这两种说法含义相同）\n",
    "* 正则表达式可以拼接；如果A和B都是正则表达式，那么AB也是正则表达式。通常，如果字符串P匹配A并且另一个字符串Q匹配B，那么PQ到可以匹配AB。除非A或者B鑃低优先级操作，A和B存在边界条件；或者命名组引用。所以，复杂表达式可以很容易的从这里描述的简单源语表达式构建。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下是正则表达式的简要说明：\n",
    "* 正则表达式可以包含普通或者特殊字符。约大部分普通字符，比如'A','a'，或者'0'，都是最简单的正则表达式。它们就匹配自身。你可以拼接普通字符，所以last匹配字符串'last'。\n",
    "* 有些字符，比如'|'或者'('，属于特殊字符。特殊字符即可以表示它的普通含义，也可以影响它旁边的正则表达式的解释。\n",
    "* 重复修饰符（*,+,?,{m,n},等）不能直接嵌套。这样避免了非法贪婪后缀?修饰符，和其他实现中的修饰符产生的多义性。要应用一个内层重复嵌套，可以使用括号。比如，表达式(?:a{6})*匹配6个'a'字符重复任意次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊字符是：\n",
    "* . :（点）:在默认模式，匹配除了换行的任意字符。如果指定了标签DOTALL,它将匹配包括换行符的任意字符。\n",
    "* ^ :（插入符号）:匹配字符串的开头，并且在MULTILINE模式也匹配换行后的首个符号。\n",
    "* $ ：匹配字符串尾或者换行符的前一个字符，在MULTILINE模式匹配换行符的前一个字符foo 匹配 'foo' 和 'foobar' , 但正则 foo$ 只匹配 'foo'。更有趣的是， 在 'foo1\\nfoo2\\n' 搜索 foo.$ ，通常匹配 'foo2' ，但在 MULTILINE 模式 ，可以匹配到 'foo1' ；在 'foo\\n' 搜索 $ 会找到两个空串：一个在换行前，一个在字符串最后。\n",
    "* * ：对它前面的正则式匹配0到任意次重复， 尽量多的匹配字符串。 ab* 会匹配 'a'， 'ab'， 或者 'a'``后面跟随任意个 ``'b'。\n",
    "* + ：对它前面的正则式匹配1到任意次重复。 ab+ 会匹配 'a' 后面跟随1个以上到任意个 'b'，它不会匹配 'a'。\n",
    "* ? : 对它前面的正则式匹配0到1次重复。 ab? 会匹配 'a' 或者 'ab'。\n",
    "* *?，+?，?? ：'*', '+'，和 '?' 修饰符都是 贪婪的；它们在字符串进行尽可能多的匹配。有时候并不需要这种行为。如果正则式 <.*> 希望找到 '<a> b <c>'，它将会匹配整个字符串，而不仅是 '<a>'。在修饰符之后添加 ? 将使样式以 非贪婪`方式或者 :dfn:`最小 方式进行匹配； 尽量 少 的字符将会被匹配。 使用正则式 <.*?> 将会仅仅匹配 '<a>'。\n",
    "* {m}: 对其之前的正则式指定匹配 m 个重复；少于 m 的话就会导致匹配失败。比如， a{6} 将匹配6个 'a' , 但是不能是5个。\n",
    "* {m,n}:对正则式进行 m 到 n 次匹配，在 m 和 n 之间取尽量多。 比如，a{3,5} 将匹配 3 到 5个 'a'。忽略 m 意为指定下界为0，忽略 n 指定上界为无限次。 比如 a{4,}b 将匹配 'aaaab' 或者1000个 'a' 尾随一个 'b'，但不能匹配 'aaab'。逗号不能省略，否则无法辨别修饰符应该忽略哪个边界。\n",
    "* {m,n}? : 前一个修饰符的非贪婪模式，只匹配尽量少的字符次数。比如，对于 'aaaaaa'， a{3,5} 匹配 5个 'a' ，而 a{3,5}? 只匹配3个 'a'。    \n",
    "* \\ : 转义特殊字符（允许你匹配 '*', '?', 或者此类其他），或者表示一个特殊序列；特殊序列之后进行讨论。\n",
    "\n",
    "如果你没有使用原始字符串（ r'raw' ）来表达样式，要牢记Python也使用反斜杠作为转义序列；如果转义序列不被Python的分析器识别，反斜杠和字符才能出现在字符串中。如果Python可以识别这个序列，那么反斜杠就应该重复两次。这将导致理解障碍，所以高度推荐，就算是最简单的表达式，也要使用原始字符串。\n",
    "#### []\n",
    "* 用于表示一个字符集合。在一个集合中：\n",
    "* 字符可以单独列出，比如 [amk] 匹配 'a'， 'm'， 或者 'k'。\n",
    "* 可以表示字符范围，通过用 '-' 将两个字符连起来。比如 [a-z] 将匹配任何小写ASCII字符， [0-5][0-9] 将匹配从 00 到 59 的两位数字， [0-9A-Fa-f] 将匹配任何十六进制数位。 如果 - 进行了转义 （比如 [a\\-z]）或者它的位置在首位或者末尾（如 [-a] 或 [a-]），它就只表示普通字符 '-'。\n",
    "* 特殊字符在集合中，失去它的特殊含义。比如 [(+*)] 只会匹配这几个文法字符 '(', '+', '*', or ')'。\n",
    "* 字符类如 \\w 或者 \\S (如下定义) 在集合内可以接受，它们可以匹配的字符由 ASCII 或者 LOCALE 模式决定。\n",
    "* 不在集合范围内的字符可以通过 取反 来进行匹配。如果集合首字符是 '^' ，所有 不 在集合内的字符将会被匹配，比如 [^5] 将匹配所有字符，除了 '5'， [^^] 将匹配所有字符，除了 '^'. ^ 如果不在集合首位，就没有特殊含义。\n",
    "* 在集合内要匹配一个字符 ']'，有两种方法，要么就在它之前加上反斜杠，要么就把它放到集合首位。比如， [()[\\]{}] 和 []()[{}] 都可以匹配括号。\n",
    "* | :A|B， A 和 B 可以是任意正则表达式，创建一个正则表达式，匹配 A 或者 B. 任意个正则表达式可以用 '|' 连接。它也可以在组合（见下列）内使用。扫描目标字符串时， '|' 分隔开的正则样式从左到右进行匹配。当一个样式完全匹配时，这个分支就被接受。意思就是，一旦 A 匹配成功， B 就不再进行匹配，即便它能产生一个更好的匹配。或者说，'|' 操作符绝不贪婪。 如果要匹配 '|' 字符，使用 \\|， 或者把它包含在字符集里，比如 [|].\n",
    "* (...):（组合），匹配括号内的任意正则表达式，并标识出组合的开始和结尾。匹配完成后，组合的内容可以被获取，并可以在之后用 \\number 转义序列进行再次匹配，之后进行详细说明。要匹配字符 '(' 或者 ')', 用 \\( 或 \\), 或者把它们包含在字符集合里: [(], [)].\n",
    "* (?…):( 'a', 'i', 'L', 'm', 's', 'u', 'x' 中的一个或多个) 这个组合匹配一个空字符串；这些字符对正则表达式设置以下标记 re.A (只匹配ASCII字符), re.I (忽略大小写), re.L (语言依赖), re.M (多行模式), re.S (点dot匹配全部字符), re.U (Unicode匹配), and re.X (冗长模式)。 (这些标记在 模块内容 中描述) 如果你想将这些标记包含在正则表达式中，这个方法就很有用，免去了在 re.compile() 中传递 flag 参数。标记应该在表达式字符串首位表示。\n",
    "*  (?aiLmsux-imsx:…): ('a', 'i', 'L', 'm', 's', 'u', 'x' 中的0或者多个， 之后可选跟随 '-' 在后面跟随 'i' , 'm' , 's' , 'x' 中的一到多个 .) 这些字符为表达式的其中一部分 设置 或者 去除 相应标记 re.A (只匹配ASCII), re.I (忽略大小写), re.L (语言依赖), re.M (多行), re.S (点匹配所有字符), re.U (Unicode匹配), and re.X (冗长模式)。(标记描述在 模块内容 .)'a', 'L' and 'u' 作为内联标记是相互排斥的， 所以它们不能结合在一起，或者跟随 '-' 。 当他们中的某个出现在内联组中，它就覆盖了括号组内的匹配模式。在Unicode样式中， (?a:...) 切换为 只匹配ASCII， (?u:...) 切换为Unicode匹配 (默认). 在byte样式中 (?L:...) 切换为语言依赖模式， (?a:...) 切换为 只匹配ASCII (默认)。这种方式只覆盖组合内匹配，括号外的匹配模式不受影响。\n",
    "* (?P=name):   反向引用一个命名组合；它匹配前面那个叫 name 的命名组中匹配到的串同样的字串。\n",
    "* (?#…) : 注释；里面的内容会被忽略。\n",
    "* (?=…): 匹配 … 的内容，但是并不消费样式的内容。这个叫做 lookahead assertion。比如， Isaac (?=Asimov) 匹配 'Isaac ' 只有在后面是 'Asimov' 的时候。\n",
    "* (?!…): 匹配 … 不符合的情况。这个叫 negative lookahead assertion （前视取反）。比如说， Isaac (?!Asimov) 只有后面 不 是 'Asimov' 的时候才匹配 'Isaac ' 。\n",
    "*  (?<=…): 匹配字符串的当前位置，它的前面匹配 … 的内容到当前位置。这叫:dfn:positive lookbehind assertion （正向后视断定）。 (?<=abc)def 会在 'abcdef' 中找到一个匹配，因为后视会往后看3个字符并检查是否包含匹配的样式。包含的匹配样式必须是定长的，意思就是 abc 或 a|b 是允许的，但是 a* 和 a{3,4} 不可以。注意以 positive lookbehind assertions 开始的样式，如 (?<=abc)def ，并不是从 a 开始搜索，而是从 d 往回看的。你可能更加愿意使用 search() 函数，而不是 match() 函数： \n",
    "                                                                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "m = re.search('(?<=abc)def','abcdef')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这个例子搜索一个跟随在连字符后的单词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'egg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.search(r'(?<=-)\\w+','spam-egg')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在3.5版更改：添加定长组合引用的支持\n",
    "* (?<!…)：匹配当前位置之前不是 ... 的样式。这个叫 negative lookbehind assertion （后视断定取非）。类似正向后视断定，包含的样式匹配必须是定长的。由 negative lookbehind assertion 开始的样式可以从字符串搜索开始的位置进行匹配。\n",
    "* (?(id/name)yes-pattern|no-pattern) ：如果给定的 id 或 name 存在，将会尝试匹配 yes-pattern ，否则就尝试匹配 no-pattern，no-pattern 可选，也可以被忽略。比如， (<)?(\\w+@\\w+(?:\\.\\w+)+)(?(1)>|$) 是一个email样式匹配，将匹配 '<user@host.com>' 或 'user@host.com' ，但不会匹配 '<user@host.com' ，也不会匹配 'user@host.com>'。\n",
    "* \\number：匹配数字代表的组合。每个括号是一个组合，组合从1开始编号。比如 (.+) \\1 匹配 'the the' 或者 '55 55', 但不会匹配 'thethe' (注意组合后面的空格)。这个特殊序列只能用于匹配前面99个组合。如果 number 的第一个数位是0， 或者 number 是三个八进制数，它将不会被看作是一个组合，而是八进制的数字值。在 '[' 和 ']' 字符集合内，任何数字转义都被看作是字符。\n",
    "* \\A ：只匹配字符串开始。\n",
    "* \\b ： 匹配空字符串，但只在单词开始或结尾的位置。一个单词被定义为一个单词字符的序列。注意，通常 \\b 定义为 \\w 和 \\W 字符之间，或者 \\w 和字符串开始/结尾的边界， 意思就是 r'\\bfoo\\b' 匹配 'foo', 'foo.', '(foo)', 'bar foo baz' 但不匹配 'foobar' 或者 'foo3'。默认情况下，Unicode字母和数字是在Unicode样式中使用的，但是可以用 ASCII 标记来更改。如果 LOCALE 标记被设置的话，词的边界是由当前语言区域设置决定的，\\b 表示退格字符，以便与Python字符串文本兼容。\n",
    "* \\B ：匹配空字符串，但 不 能在词的开头或者结尾。意思就是 r'py\\B' 匹配 'python', 'py3', 'py2', 但不匹配 'py', 'py.', 或者 'py!'. \\B 是 \\b 的取非，所以Unicode样式的词语是由Unicode字母，数字或下划线构成的，虽然可以用 ASCII 标志来改变。如果使用了 LOCALE 标志，则词的边界由当前语言区域设置。\n",
    "* \\d : 对于 Unicode (str) 样式：匹配任何Unicode十进制数（就是在Unicode字符目录[Nd]里的字符）。这包括了 [0-9] ，和很多其他的数字字符。如果设置了 ASCII 标志，就只匹配 [0-9] 。对于8位(bytes)样式：匹配任何十进制数，就是 [0-9]。 \n",
    "* \\D : 匹配任何非十进制数字的字符。就是 \\d 取非。 如果设置了 ASCII 标志，就相当于 [^0-9] 。\n",
    "* \\s : 对于 Unicode (str) 样式：\n",
    "匹配任何Unicode空白字符（包括 [ \\t\\n\\r\\f\\v] ，还有很多其他字符，比如不同语言排版规则约定的不换行空格）。如果 ASCII 被设置，就只匹配 [ \\t\\n\\r\\f\\v] 。对于8位(bytes)样式：匹配ASCII中的空白字符，就是 [ \\t\\n\\r\\f\\v] 。\n",
    "* \\S : 匹配任何非空白字符。就是 \\s 取非。如果设置了 ASCII 标志，就相当于 [^ \\t\\n\\r\\f\\v] 。\n",
    "* \\w : 对于 Unicode (str) 样式：匹配Unicode词语的字符，包含了可以构成词语的绝大部分字符，也包括数字和下划线。如果设置了 ASCII 标志，就只匹配 [a-zA-Z0-9_] 。对于8位(bytes)样式：匹配ASCII字符中的数字和字母和下划线，就是 [a-zA-Z0-9_] 。如果设置了 LOCALE 标记，就匹配当前语言区域的数字字母和下划线。\n",
    "* \\W : 匹配任何不是单词字符的字符。 这与 \\w 正相反。 如果使用了 ASCII 旗标，这就等价于 [^a-zA-Z0-9_]。 如果使用了 LOCALE 旗标，则会匹配在当前区域设置中不是字母数字又不是下划线的字符。\n",
    "* \\Z : 只匹配字符串尾。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模块内容\n",
    "模块定义了几个函数，常量，和一个例外。有些函数是编译后的正则表达式方法的简化版本（少了一些特性）。绝大部分重要的应用，总是会先将正则表达式编译，之后在进行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = re.comile(pattern)\n",
    "result = prog.match(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "等价于"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.match(pattern,string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如果需要多次使用这个正则表达式的话，使用 re.compile() 和保存这个正则对象以便复用，可以让程序更加高效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* re.A\n",
    "* re.ASCII ：让 \\w, \\W, \\b, \\B, \\d, \\D, \\s 和 \\S 只匹配ASCII，而不是Unicode。这只对Unicode样式有效，会被byte样式忽略。相当于前面语法中的内联标志 (?a) 。\n",
    "* re.DEBUG ：显示编译时的debug信息，没有内联标记。\n",
    "* re.I\n",
    "* re.IGNORECASE ：进行忽略大小写匹配；表达式如 [A-Z] 也会匹配小写字符。Unicode匹配（比如 Ü 匹配 ü）同样有用，除非设置了 re.ASCII 标记来禁用非ASCII匹配。当前语言区域不会改变这个标记，除非设置了 re.LOCALE 标记。这个相当于内联标记 (?i) 。\n",
    "* re.L\n",
    "* re.LOCALE ：由当前语言区域决定 \\w, \\W, \\b, \\B 和大小写敏感匹配。这个标记只能对byte样式有效。这个标记不推荐使用，因为语言区域机制很不可靠，它一次只能处理一个 \"习惯”，而且只对8位字节有效。Unicode匹配在Python 3 里默认启用，并可以处理不同语言。 这个对应内联标记 (?L) 。\n",
    "* re.M\n",
    "* re.MULTILINE ：设置以后，样式字符 '^' 匹配字符串的开始，和每一行的开始（换行符后面紧跟的符号）；样式字符 匹配字符串尾，和每一行的结（换行符前面那个符号）。默认情况下，’^’ 匹配字符串头，$ 匹配字符串尾。对应内联标记 (?m) 。\n",
    "* re.S\n",
    "* re.DOTALL ：让 '.' 特殊字符匹配任何字符，包括换行符；如果没有这个标记，'.' 就匹配 除了 换行符的其他任意字符。对应内联标记 (?s) 。\n",
    "* re.X\n",
    "* re.VERBOSE ：这个标记允许你编写更具可读性更友好的正则表达式。通过分段和添加注释。空白符号会被忽略，除非在一个字符集合当中或者由反斜杠转义，或者在 *?, (?: or (?P<…> 分组之内。当一个行内有 # 不在字符集和转义序列，那么它之后的所有字符都是注释。\n",
    "* re.search(pattern, string, flags=0) ： 扫描整个 字符串 找到匹配样式的第一个位置，并返回一个相应的 匹配对象。如果没有匹配，就返回一个 None ； 注意这和找到一个零长度匹配是不同的。\n",
    "* re.match(pattern, string, flags=0) ： 如果 string 开始的0或者多个字符匹配到了正则表达式样式，就返回一个相应的 匹配对象 。 如果没有匹配，就返回 None ；注意它跟零长度匹配是不同的。\n",
    "* re.fullmatch(pattern, string, flags=0) : 如果整个 string 匹配到正则表达式样式，就返回一个相应的 匹配对象 。 否则就返回一个 None ；注意这跟零长度匹配是不同的。\n",
    "* re.split(pattern, string, maxsplit=0, flags=0) : 用 pattern 分开 string 。 如果在 pattern 中捕获到括号，那么所有的组里的文字也会包含在列表里。如果 maxsplit 非零， 最多进行 maxsplit 次分隔， 剩下的字符全部返回到列表的最后一个元素。\n",
    "                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Words', 'words', 'words', '']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split(r'\\W+','Words,words,words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Words', ',', 'words', ',', 'words', '.', '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'(\\W+)','Words,words,words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Words', 'words,words.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\W+','Words,words,words.',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '3', '9']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('[a-f]+','0a3B9',flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如果分隔符里有捕获组合,并且匹配到字符串的开始,那么结果将会以一个空字符串开始.对于结尾也是一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '...', 'words', ',', 'words', '...', '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'(\\W+)','...words,words...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这样的话,分隔组将会出现在结果列表中同样的位置.\n",
    "### 样式的空匹配将分开字符串,但只在不相临的状况生效."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'Words', ',', 'words', ',', 'words', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\b','Words,words,words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', 'w', 'o', 'r', 'd', 's', '', '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\W*','...words...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'(\\W*)','...words...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则表达式例子\n",
    "* 在这个例子中，我们使用以下辅助函数来更好地显示匹配对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaymatch(match):\n",
    "    if match is None:\n",
    "        return None\n",
    "    return '<Match: %r,groups=%r>' % (match.group(),match.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 假设你在写一个补克程序，一个玩家的一手牌为五个字符的串，每个字符表示一张牌，\"a\" 就是 A, \"k\" K， \"q\" Q, \"j\" J, \"t\" 为 10, \"2\" 到 \"9\" 表示2 到 9。要看给定的字符串是否有效，我们可以按照以下步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = re.compile(r\"^[a2-9tjqk]{5$}\")\n",
    "displaymatch(valid.match(\"akt5q\")) # valid.\n",
    "displaymatch(valid.match(\"akt5e\")) # Invalid.\n",
    "displaymatch(valid.match(\"akt\"))\n",
    "displaymatch(valid.match(\"727ak\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最后一手牌，\"727ak\" ，包含了一个对子，或者两张同样数值的牌。要用正则表达式匹配它，应该使用向后引用如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<Match: '717',groups=('7',)>\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = re.compile(r\".*(.).*\\1\")\n",
    "displaymatch(pair.match(\"717ak\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "displaymatch(pair.match(\"718ak\")) # No pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<Match: '354aa',groups=('a',)>\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displaymatch(pair.match(\"354aa\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要找出对子由什么牌组成，开发者可以按照下面的方式来使用匹配对象的 group() 方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = re.compile(r\".*(.).*\\1\")\n",
    "pair.match(\"717ak\").group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Error because re.match() returns None,which doesn't have a group() method:\n",
    "pair.match(\"354aa\").group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search() vs. match()\n",
    "* Python 提供了两种不同的操作：基于 re.match() 检查字符串开头，或者 re.search() 检查字符串的任意位置（默认Perl中的行为）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(2, 3), match='c'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"c\",'abcdef') # No match\n",
    "re.search(\"c\",'abcdef')  # Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在 search() 中，可以用 '^' 作为开始来限制匹配到字符串的首位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='a'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"c\",\"abcdef\") # No match\n",
    "re.search(\"^c\",\"abcdef\") # No match\n",
    "re.search(\"^a\",\"abcdef\") # match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意 MULTILINE 多行模式中函数 match() 只匹配字符串的开始，但使用 search() 和以 '^' 开始的正则表达式会匹配每行的开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(4, 5), match='X'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match('X','A\\nB\\nX',re.MULTILINE) # No match\n",
    "re.search('^X','A\\nB\\nX',re.MULTILINE) # Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立一个电话本\n",
    "* split() 将字符串用参数传递的样式分隔开。这个方法对于转换文本数据到易读而且容易修改的数据结构，是很有用的，如下面的例子证明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Ross McFluff:834.345.1254 155 Elm Street\n",
    "...\n",
    "... Ronald Heathmore:892.345.3428 436 Finley Avenue\n",
    "... Frank Burger: 925.541 7625 662 South Dlgwood Way\n",
    "...\n",
    "...\n",
    "... Heather Albrecht:548.326.4584 919 Park Place\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条目用一个或者多个换行符分开。现在我们将字符串转换为一个列表，每个非空行都有一个条目:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ross McFluff:834.345.1254 155 Elm Street',\n",
       " 'Ronald Heathmore:892.345.3428 436 Finley Avenue',\n",
       " 'Frank Burger: 925.541 7625 662 South Dlgwood Way',\n",
       " 'Heather Albrecht:548.326.4584 919 Park Place']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = re.split(\"\\n+\",text)\n",
    "entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最终，将每个条目分割为一个由名字、姓氏、电话号码和地址组成的列表。我们为 split() 使用了 maxsplit 形参，因为地址中包含有被我们作为分割模式的空格符:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'R', 'o', 'ss McFluff:834.345.1254 155 Elm Street'],\n",
       " ['', 'R', 'o', 'nald Heathmore:892.345.3428 436 Finley Avenue'],\n",
       " ['', 'F', 'r', 'ank Burger: 925.541 7625 662 South Dlgwood Way'],\n",
       " ['', 'H', 'e', 'ather Albrecht:548.326.4584 919 Park Place']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.split(\":?\",entry,3) for entry in entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字整理\n",
    "* sub() 替换字符串中出现的样式的每一个实例。这个例子证明了使用 sub() 来整理文字，或者随机化每个字符的位置，除了首位和末尾字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repl(m):\n",
    "    inner_word = list(m.group(2))\n",
    "    random.shuffle(inner_word)\n",
    "    return m.group(1) + \"\".join(inner_word) + m.group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Professor Abdolmalek,please report your absences promaptly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pssrfoeor Abaelomldk,plaese rrpeot yuor aecbsens ptrmaploy.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"(\\w)(\\w+)(\\w)\",repl,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Psfosorer Adlaeblomk,psleae reropt yuor asenbces poaptrlmy.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"(\\w)(\\w+)(\\w)\",repl,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到所有副词\n",
    "* findall() 匹配样式 所有 的出现，不仅是像 search() 中的第一个匹配。比如，如果一个作者希望找到文字中的所有副词，他可能会按照以下方法用 findall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carefully', 'quickly']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"He was carefully disguised but captured quickly by police.\"\n",
    "re.findall(r\"\\w+ly\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到所有副词和位置\n",
    "* 如果需要匹配样式的更多信息， finditer() 可以起到作用，它提供了 匹配对象 作为返回值，而不是字符串。继续上面的例子，如果一个作者希望找到所有副词和它的位置，可以按照下面方法使用 finditer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-16: carefully\n",
      "40-47: quickly\n"
     ]
    }
   ],
   "source": [
    "text = \"He was carefully disguised but captured quickly by police.\"\n",
    "for m in re.finditer(r\"\\w+ly\",text):\n",
    "    print('%02d-%02d: %s' % (m.start(),m.end(),m.group(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原始字符记法\n",
    "* 原始字符串记法 (r\"text\") 保持正则表达式正常。否则，每个正则式里的反斜杠('\\') 都必须前缀一个反斜杠来转义。比如，下面两行代码功能就是完全一致的。                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match=' ff '>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r\"\\W(.)\\1\\W\",\" ff \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match=' ff '>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"\\\\W(.)\\\\1\\\\W\",' ff ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当需要匹配一个字符反斜杠，它必须在正则表达式中转义。在原始字符串记法，就是 r\"\\\\\"。否则就必须用 \"\\\\\\\\\"，来表示同样的意思"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='\\\\'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r\"\\\\\",r\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='\\\\'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(\"\\\\\\\\\",r\"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 写一个词法分析器\n",
    "* 一个 词法器或词法分析器 分析字符串，并分类成目录组。 这是写一个编译器或解释器的第一步。\n",
    "* 文字目录是由正则表达式指定的。这个技术是通过将这些样式合并为一个主正则式，并且循环匹配来实现的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='IF', value='IF', line=2, column=4)\n",
      "Token(type='ID', value='quantity', line=2, column=7)\n",
      "Token(type='THEN', value='THEN', line=2, column=16)\n",
      "Token(type='ID', value='total', line=3, column=8)\n",
      "Token(type='ASSIGN', value=':=', line=3, column=14)\n",
      "Token(type='ID', value='total', line=3, column=17)\n",
      "Token(type='OP', value='+', line=3, column=23)\n",
      "Token(type='ID', value='price', line=3, column=25)\n",
      "Token(type='OP', value='*', line=3, column=31)\n",
      "Token(type='ID', value='quantity', line=3, column=33)\n",
      "Token(type='END', value=';', line=3, column=41)\n",
      "Token(type='ID', value='tax', line=4, column=8)\n",
      "Token(type='ASSIGN', value=':=', line=4, column=12)\n",
      "Token(type='ID', value='price', line=4, column=15)\n",
      "Token(type='OP', value='*', line=4, column=21)\n",
      "Token(type='NUMBER', value=0.05, line=4, column=23)\n",
      "Token(type='END', value=';', line=4, column=27)\n",
      "Token(type='ENDIF', value='ENDIF', line=5, column=4)\n",
      "Token(type='END', value=';', line=5, column=9)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "Token = collections.namedtuple('Token', ['type', 'value', 'line', 'column'])\n",
    "\n",
    "def tokenize(code):\n",
    "    keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'}\n",
    "    token_specification = [\n",
    "        ('NUMBER',   r'\\d+(\\.\\d*)?'),  # Integer or decimal number\n",
    "        ('ASSIGN',   r':='),           # Assignment operator\n",
    "        ('END',      r';'),            # Statement terminator\n",
    "        ('ID',       r'[A-Za-z]+'),    # Identifiers\n",
    "        ('OP',       r'[+\\-*/]'),      # Arithmetic operators\n",
    "        ('NEWLINE',  r'\\n'),           # Line endings\n",
    "        ('SKIP',     r'[ \\t]+'),       # Skip over spaces and tabs\n",
    "        ('MISMATCH', r'.'),            # Any other character\n",
    "    ]\n",
    "    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n",
    "    line_num = 1\n",
    "    line_start = 0\n",
    "    for mo in re.finditer(tok_regex, code):\n",
    "        kind = mo.lastgroup\n",
    "        value = mo.group()\n",
    "        column = mo.start() - line_start\n",
    "        if kind == 'NUMBER':\n",
    "            value = float(value) if '.' in value else int(value)\n",
    "        elif kind == 'ID' and value in keywords:\n",
    "            kind = value\n",
    "        elif kind == 'NEWLINE':\n",
    "            line_start = mo.end()\n",
    "            line_num += 1\n",
    "            continue\n",
    "        elif kind == 'SKIP':\n",
    "            continue\n",
    "        elif kind == 'MISMATCH':\n",
    "            raise RuntimeError(f'{value!r} unexpected on line {line_num}')\n",
    "        yield Token(kind, value, line_num, column)\n",
    "\n",
    "statements = '''\n",
    "    IF quantity THEN\n",
    "        total := total + price * quantity;\n",
    "        tax := price * 0.05;\n",
    "    ENDIF;\n",
    "'''\n",
    "\n",
    "for token in tokenize(statements):\n",
    "    print(token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
